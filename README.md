# ü´Å Classifica√ß√£o de Patologias em Raio-X Tor√°cico
### Ligia ‚Äì Liga Acad√™mica de Intelig√™ncia Artificial ¬∑ UFPE ¬∑ Processo Seletivo 2026

**Trilha:** Vis√£o Computacional | **M√©trica:** ROC AUC | **Resultado:** `0.99129` no leaderboard Kaggle

[![Python](https://img.shields.io/badge/Python-3.10%2B-blue?logo=python)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.x-orange?logo=pytorch)](https://pytorch.org/)
[![Kaggle](https://img.shields.io/badge/Kaggle-ROC%20AUC%200.99129-20BEFF?logo=kaggle)](https://www.kaggle.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-green)](LICENSE)

---

## üìã Sum√°rio

1. [Vis√£o Geral](#-vis√£o-geral)
2. [Resultados](#-resultados)
3. [Estrutura do Reposit√≥rio](#-estrutura-do-reposit√≥rio)
4. [Instala√ß√£o e Ambiente](#-instala√ß√£o-e-ambiente)
5. [Dataset](#-dataset)
6. [Pipeline Completo](#-pipeline-completo)
7. [Como Reproduzir](#-como-reproduzir)
8. [Decis√µes T√©cnicas](#-decis√µes-t√©cnicas)
9. [An√°lise de Interpretabilidade](#-an√°lise-de-interpretabilidade)
10. [Limita√ß√µes e Trabalhos Futuros](#-limita√ß√µes-e-trabalhos-futuros)
11. [Autor](#-autor)

---

## üî¨ Vis√£o Geral

Este projeto aborda a classifica√ß√£o bin√°ria de radiografias de t√≥rax (**NORMAL** vs **PNEUMONIA**) como parte do Desafio Individual da trilha de Vis√£o Computacional da Ligia (UFPE, 2026).

A solu√ß√£o foi constru√≠da como uma **jornada de pesquisa documentada**: cada decis√£o t√©cnica ‚Äî desde a detec√ß√£o de *shortcut learning* por vi√©s de hardware at√© a escolha do backbone por torneio controlado ‚Äî √© rastre√°vel a evid√™ncia experimental reproduz√≠vel.

### Destaques Metodol√≥gicos

- üîç **Detec√ß√£o original de vi√©s de hardware**: an√°lise estat√≠stica de ru√≠do de fundo (desvio padr√£o em cantos da imagem) revelou que imagens NORMAL e PNEUMONIA foram capturadas com equipamentos distintos, criando uma "assinatura de sensor" que poderia ser aprendida como *shortcut* pelo modelo
- üõ°Ô∏è **Anti-leakage por paciente**: 23,7% dos pacientes t√™m m√∫ltiplas imagens; `StratifiedGroupKFold` garante que nenhum paciente apare√ßa em treino e valida√ß√£o simultaneamente
- ‚öóÔ∏è **Todas as decis√µes por torneio controlado**: transforms, estrat√©gia de balanceamento, backbone e pesos do ensemble ‚Äî todas escolhas baseadas em experimentos com crit√©rio de equival√™ncia estat√≠stica
- üß¨ **Ensemble heterog√™neo**: DenseNet-121 com pesos ImageNet (Mixup+LS) + DenseNet-121 com pesos especializados em >100k raio-X (TorchXRayVision), com pesos otimizados por grid search

---

## üìä Resultados

| Configura√ß√£o | ROC AUC (CV 5-fold) | Spread |
|---|---|---|
| DenseNet-121 baseline (torneio) | 0,9833 | ¬±0,0061 |
| + Fine-tuning gradual (3 fases) | 0,9978 | ¬±0,0009 |
| + Mixup + Label Smoothing | 0,9983 | ¬±0,0009 |
| TorchXRayVision v1 (5/5/5 √©pocas) | 0,9949 | ¬±0,0007 |
| TorchXRayVision v2 (5/7/10 √©pocas) | 0,9972 | ¬±0,0008 |
| DenseNet-121 Augmenta√ß√£o Agressiva | 0,9978 | ¬±0,0016 |
| EfficientNet-B4 (380√ó380) | 0,9969 | ¬±0,0008 |
| **Ensemble √≥timo (w=0,70/0,30)** | **0,9987** | **‚Äî** |
| Holdout interno (802 imgs / 519 pac.) | 0,9954 | ‚Äî |
| **üèÜ Kaggle Leaderboard** | **0,99129** | ‚Äî |

> **Nota sobre generaliza√ß√£o:** o delta de +0,0028 entre AUC m√©dio de CV (0,9982) e holdout confirma aus√™ncia de overfitting estrutural. O plateau de 0,9987 com 4 modelos distintos indica que o teto est√° no volume de dados (4.430 imagens de treino), n√£o na capacidade dos modelos.

---

## üìÅ Estrutura do Reposit√≥rio

```
.
‚îú‚îÄ‚îÄ Notebook_final.ipynb          # Notebook principal ‚Äî pipeline completo e documentado
‚îú‚îÄ‚îÄ requirements.txt              # Depend√™ncias do projeto
‚îú‚îÄ‚îÄ README.md                     # Este arquivo
‚îÇ
‚îú‚îÄ‚îÄ checkpoints/                  # Pesos dos modelos treinados
‚îÇ   ‚îú‚îÄ‚îÄ densenet121_fold1.pt
‚îÇ   ‚îú‚îÄ‚îÄ densenet121_fold2.pt
‚îÇ   ‚îú‚îÄ‚îÄ densenet121_fold3.pt
‚îÇ   ‚îú‚îÄ‚îÄ densenet121_fold4.pt
‚îÇ   ‚îú‚îÄ‚îÄ densenet121_fold5.pt
‚îÇ   ‚îú‚îÄ‚îÄ txrv_fold1.pt
‚îÇ   ‚îú‚îÄ‚îÄ txrv_fold2.pt
‚îÇ   ‚îú‚îÄ‚îÄ txrv_fold3.pt
‚îÇ   ‚îú‚îÄ‚îÄ txrv_fold4.pt
‚îÇ   ‚îî‚îÄ‚îÄ txrv_fold5.pt
‚îÇ
‚îú‚îÄ‚îÄ data/                         # (n√£o inclu√≠da ‚Äî ver se√ß√£o Dataset)
‚îÇ   ‚îú‚îÄ‚îÄ train/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ NORMAL/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ PNEUMONIA/
‚îÇ   ‚îî‚îÄ‚îÄ test_images/
‚îÇ
‚îú‚îÄ‚îÄ processed/                    # Dataset pr√©-processado (gerado pela C√©lula de Pr√©-Processamento)
‚îÇ   ‚îú‚îÄ‚îÄ train/
‚îÇ   ‚îî‚îÄ‚îÄ test/
‚îÇ
‚îî‚îÄ‚îÄ submissions/
    ‚îî‚îÄ‚îÄ submission_final.csv      # Arquivo de submiss√£o gerado
```

---

## ‚öôÔ∏è Instala√ß√£o e Ambiente

### Pr√©-requisitos

- Python 3.10+
- CUDA 11.8+ (recomendado; o c√≥digo detecta automaticamente CPU como fallback)
- ~16 GB de VRAM para reprodu√ß√£o completa (treinado em Tesla P100-PCIE-16GB)

### Instala√ß√£o

```bash
# Clone o reposit√≥rio
git clone https://github.com/iceb/ligia-xray-classification.git
cd ligia-xray-classification

# Crie e ative um ambiente virtual
python -m venv .venv
source .venv/bin/activate          # Linux/macOS
# .venv\Scripts\activate           # Windows

# Instale as depend√™ncias
pip install -r requirements.txt
```

### `requirements.txt`

```
torch==2.1.0
torchvision==0.16.0
torchxrayvision==1.4.0
scikit-learn==1.3.2
numpy==1.24.4
pandas==2.1.4
Pillow==10.1.0
opencv-python==4.8.1.78
matplotlib==3.8.2
tqdm==4.66.1
timm==0.9.12
scipy==1.11.4
```

> Para ambiente Kaggle, todas as depend√™ncias s√£o instaladas diretamente no notebook. O TorchXRayVision √© instalado via `pip install torchxrayvision` no in√≠cio da se√ß√£o correspondente.

---

## üìÇ Dataset

O dataset √© disponibilizado exclusivamente via competi√ß√£o Kaggle (acesso pelo link oficial do processo seletivo da Ligia).

**Estrutura ap√≥s download:**
```
train/
  NORMAL/      ‚Üí 1.349 imagens
  PNEUMONIA/   ‚Üí 3.883 imagens (2.530 bacterianas + 1.345 virais)
test_images/   ‚Üí 624 imagens
train.csv      ‚Üí metadados de treino
test.csv       ‚Üí metadados de teste
```

**Estat√≠sticas relevantes:**
- 5.232 imagens de treino, 624 de teste
- Desbalanceamento de 2,88√ó (PNEUMONIA/NORMAL)
- 3.458 pacientes √∫nicos ‚Äî 23,7% com m√∫ltiplas imagens (m√°x: 30 por paciente)
- **Vi√©s de hardware detectado:** ru√≠do de fundo estatisticamente diferente entre classes

---

## üîÑ Pipeline Completo

O `Notebook_final.ipynb` est√° organizado em se√ß√µes sequenciais e autodocumentadas:

### 1. Configura√ß√£o e Reprodutibilidade
```python
SEED = 42
# Sementes fixadas em: Python, NumPy, PyTorch (CPU + CUDA), CuDNN determin√≠stico
```

### 2. An√°lise Explorat√≥ria de Dados (EDA)
- Verifica√ß√£o de integridade (PIL.Image.verify ‚Äî 0 arquivos corrompidos em 5.856)
- An√°lise de desbalanceamento e impacto no ROC AUC ing√™nuo (piso 74,2%)
- **Detec√ß√£o de vi√©s de hardware** (an√°lise estat√≠stica de ru√≠do, N=50/classe)
- An√°lise espectral por classe (histogramas m√©dios ‚Äî proje√ß√£o do perfil de erros)
- **An√°lise de estrutura por paciente** (identifica√ß√£o de IDs duplicados via nomenclatura)

### 3. Pr√©-Processamento
| Etapa | T√©cnica | Justificativa |
|---|---|---|
| Redimensionamento | Letterboxing para 224√ó224 | Preserva propor√ß√µes anat√¥micas |
| Contraste | CLAHE (clipLimit=2,0, tile=8√ó8) | Realce local sem amplificar ru√≠do t√©rmico |
| Ru√≠do | **NLMeans h=3** (vencedor do torneio) | Melhor Score de Converg√™ncia (41,71) entre 3 candidatos |
| Normaliza√ß√£o | ImageNet (mean/std por canal) | Compatibilidade com backbones pr√©-treinados |

> O torneio de filtragem usa um **Score de Converg√™ncia** customizado: menor sobreposi√ß√£o estat√≠stica das distribui√ß√µes de brilho e ru√≠do entre classes = vi√©s de hardware mais neutralizado.

### 4. Valida√ß√£o Cruzada Anti-Leakage
```python
from sklearn.model_selection import StratifiedGroupKFold, StratifiedShuffleSplit

# Holdout isolado ANTES de qualquer treinamento
sss = StratifiedShuffleSplit(n_splits=1, test_size=0.15, random_state=SEED)

# 5 folds garantindo isolamento por patient_id
sgkf = StratifiedGroupKFold(n_splits=5)
```

### 5. Torneios de Sele√ß√£o (todos com crit√©rio de equival√™ncia estat√≠stica)

**Torneio de Transforms** (EfficientNet-B0 proxy, 2 folds, 2 √©pocas):
- Pipeline A (sem augmenta√ß√£o): `0,9481 ¬± 0,0256` ‚úÖ Adotado por parcim√¥nia
- Pipeline B (augmenta√ß√£o geom√©trica): `0,9428 ¬± 0,0224`

**Torneio de Backbones** (599 imagens, 3 folds, 5 √©pocas, backbone congelado):

| Backbone | AUC M√©dio | Std |
|---|---|---|
| EfficientNet-B0 | 0,9604 | 0,0117 |
| EfficientNet-B2 (260√ó260) | 0,9782 | 0,0180 |
| ResNet-50 | 0,9533 | 0,0101 |
| **DenseNet-121** ‚úÖ | **0,9833** | **0,0061** |

**Torneio de Balanceamento** (599 imagens, 3 folds, 5 √©pocas):
- Sem balanceamento: `0,9899 ¬± 0,0043`
- WeightedRandomSampler: `0,9896 ¬± 0,0109`
- **pos_weight=2,91** ‚úÖ: `0,9868 ¬± 0,0062` ‚Äî menor spread, adotado por parcim√¥nia

### 6. Fine-Tuning Gradual (DenseNet-121 + Mixup + Label Smoothing)

```
Fase 1 ‚Äî cabe√ßa         (1.025 params,     lr=1e-3, 5 √©pocas)
Fase 2 ‚Äî denseblock4    (2.161.153 params,  lr=1e-4, 5 √©pocas)  ‚Üê maior salto
Fase 3 ‚Äî backbone full  (6.954.881 params,  lr=1e-5, 5 √©pocas)
```

**Regulariza√ß√£o:** Mixup Œ±=0,2 + Label Smoothing Œµ=0,1 (t√©cnicas ortogonais)
- Antes: loss de treino na Fase 3 colapsa para `0,002‚Äì0,010` (memoriza√ß√£o)
- Depois: loss estabiliza em `0,165‚Äì0,183` (memoriza√ß√£o contida)

### 7. TorchXRayVision (pesos especializados em raio-X)

```python
import torchxrayvision as xrv

model = xrv.models.DenseNet(weights="densenet121-res224-all")
# Adapta√ß√£o: conv0 1‚Üí3 canais (replica√ß√£o/3), classifier 18‚Üí1 sa√≠da
```

- Pr√©-treinado em: NIH ChestX-ray14 + CheXpert + MIMIC-CXR + PadChest (>100k raio-X)
- v1 (5/5/5 √©pocas): AUC `0,9949` ‚Äî converg√™ncia insuficiente
- **v2 (5/7/10 √©pocas): AUC `0,9972 ¬± 0,0008`** ‚Äî menor spread do projeto

### 8. Ensemble com Otimiza√ß√£o de Pesos

```python
# Grid search sobre predi√ß√µes de valida√ß√£o cruzada (nunca sobre o holdout)
# Passos de 0,05 em w_txrv de 0,00 a 1,00
# Peso √≥timo: w_mixupLS=0.70, w_txrv=0.30 ‚Üí AUC m√©dio = 0,9987
```

> O plateau √© largo (w_txrv entre 0,25‚Äì0,50 produz AUC equivalente), indicando que a diversidade de origem dos pesos (ImageNet vs raio-X) √© o fator relevante, n√£o o peso exato.

---

## ‚ñ∂Ô∏è Como Reproduzir

### Op√ß√£o A ‚Äî Kaggle (recomendado, ambiente original)

1. Fa√ßa fork da competi√ß√£o e adicione o dataset como input
2. Fa√ßa upload do `Notebook_final.ipynb`
3. Ative GPU P100 (Kaggle oferece gratuitamente)
4. Execute todas as c√©lulas em ordem (`Run All`)
5. O arquivo `submission_final.csv` √© gerado automaticamente na √∫ltima c√©lula

### Op√ß√£o B ‚Äî Ambiente Local

```bash
# 1. Configure o ambiente (ver se√ß√£o Instala√ß√£o)

# 2. Baixe o dataset via Kaggle CLI
pip install kaggle
kaggle competitions download -c [nome-da-competicao-ligia]
unzip *.zip -d data/

# 3. Execute o notebook
jupyter notebook Notebook_final.ipynb

# 4. Execute as c√©lulas em ordem:
#    - C√©lula de Configura√ß√£o (SEED, paths)
#    - EDA (an√°lise explorat√≥ria)
#    - Pr√©-Processamento (gera pasta processed/)
#    - Cross Validation Setup
#    - Torneios (transforms, balanceamento, backbone)
#    - Treinamento DenseNet-121 + Mixup+LS (salva checkpoints/)
#    - Treinamento TorchXRayVision v2 (salva checkpoints_txrv/)
#    - Ensemble + Gera√ß√£o de Submiss√£o
```

### Apenas Infer√™ncia (com checkpoints pr√©-treinados)

```python
import torch
from torchvision import models

# Carregar modelo Mixup+LS
model_mixup = models.densenet121(pretrained=False)
model_mixup.classifier = torch.nn.Linear(1024, 1)
model_mixup.load_state_dict(torch.load('checkpoints/densenet121_fold1.pt'))
model_mixup.eval()

# Para ensemble: m√©dia ponderada das predi√ß√µes
# pred_final = 0.70 * pred_mixup + 0.30 * pred_txrv
```

> Todos os checkpoints foram salvos com `torch.save(model.state_dict(), path)` e s√£o compat√≠veis com PyTorch ‚â• 2.0.

---

## üß† Decis√µes T√©cnicas

### Por que DenseNet-121?

As conex√µes densas ‚Äî cada camada recebe gradiente direto de todas as anteriores ‚Äî entregam dois benef√≠cios cr√≠ticos para este dom√≠nio:

1. **Converg√™ncia acelerada em texturas finas:** no torneio de 5 √©pocas, o DenseNet j√° ultrapassava AUC 0,91 enquanto concorrentes oscilavam abaixo de 0,70
2. **Interpretabilidade por Grad-CAM:** gradientes chegam √†s camadas superficiais com menor degrada√ß√£o, produzindo mapas de sali√™ncia mais confi√°veis ‚Äî essencial para valida√ß√£o cl√≠nica

### Por que NLMeans h=3 e n√£o Filtro Bilateral?

O Filtro Bilateral preserva bordas seletivamente mas manteve disparidades residuais entre classes. Isso revelou que a fonte do vi√©s de hardware √© a **varia√ß√£o de textura global**, n√£o apenas bordas. O NLMeans com h=3 (suaviza√ß√£o leve e constante) foi mais eficaz em unificar as assinaturas de ru√≠do.

### Por que n√£o usar augmenta√ß√£o geom√©trica?

Raio-X tor√°cico imp√µe restri√ß√µes anat√¥micas r√≠gidas:
- **Flip horizontal** simula dextrocardia (posi√ß√£o invertida do cora√ß√£o ‚Äî condi√ß√£o card√≠aca rara)
- **Rota√ß√µes acima de 10¬∞** produzem incid√™ncias clinicamente inexistentes
- O CLAHE + NLMeans j√° extraiu a variabilidade essencial do dataset (comprovado pelo torneio de transforms)

### Por que Mixup + Label Smoothing s√£o complementares?

| T√©cnica | Age quando... | Gap |
|---|---|---|
| Mixup (Œ±=0,2) | Œª ~ Beta(0,2, 0,2) ‚Üí soft labels din√¢micos | Œª pr√≥ximo de 0 ou 1 ‚Üí r√≥tulos quase bin√°rios |
| Label Smoothing (Œµ=0,1) | Sempre | Cobre exatamente o gap do Mixup |

---

## üîç An√°lise de Interpretabilidade

### Evid√™ncias Indiretas (do Notebook)

Sem implementar Grad-CAM, os logs j√° fornecem evid√™ncia sobre o que o modelo aprendeu:

1. **Converg√™ncia explosiva do denseblock4** na Fase 2 (AUC 0,9878‚Üí0,9978 em 5 √©pocas) indica que representa√ß√µes de alta abstra√ß√£o sem√¢ntica capturaram padr√µes diagn√≥sticos ‚Äî infiltrados e consolida√ß√µes s√£o padr√µes espaciais de alta frequ√™ncia concentrados nas camadas mais profundas

2. **Offset de normaliza√ß√£o persistente** ap√≥s todo o pr√©-processamento:
   - NORMAL: mean `‚àí0,154 ¬± 0,256`
   - PNEUMONIA: mean `‚àí0,381 ¬± 0,347`
   
   Diferen√ßa de 0,23 unidades de desvio padr√£o compat√≠vel com hiperdensidade focal real

3. **Converg√™ncia estat√≠stica p√≥s-NLMeans** (N=300): a feature de ru√≠do de sensor foi eliminada por constru√ß√£o, tornando improv√°vel seu uso como discriminador

### Pr√≥ximo Passo ‚Äî Grad-CAM

```python
# Registrar hook na camada de maior abstra√ß√£o sem√¢ntica
target_layer = model.features.norm5

# Executar backward para a classe predita
# Sobrepor mapa √†s radiografias originais
# Validar com anota√ß√µes de radiologistas
```

> Grad-CAM sobre `features.norm5` permitiria validar clinicamente se as regi√µes de maior ativa√ß√£o coincidem com as √°reas de consolida√ß√£o marcadas por especialistas ‚Äî custo computacional zero (apenas infer√™ncia).

### Perfil de Erros

A an√°lise espectral da EDA (histogramas m√©dios por classe) projeta com precis√£o quais casos s√£o mais dif√≠ceis:

- **Casos mais dif√≠ceis:** PNEUMONIA viral inicial ‚Äî infiltrado intersticial sutil, sobreposi√ß√£o espectral alta com NORMAL
- **Casos mais f√°ceis:** PNEUMONIA bacteriana consolidada ‚Äî deslocamento para tons claros (150‚Äì230), baixa sobreposi√ß√£o com NORMAL

O pos_weight=2,91 resulta em Recall >0,98 para PNEUMONIA em todos os folds. Em produ√ß√£o, o threshold de 0,5 deve ser ajustado via curva Precision-Recall para o contexto cl√≠nico espec√≠fico.

---

## ‚ö†Ô∏è Limita√ß√µes e Trabalhos Futuros

| Limita√ß√£o | Impacto | Solu√ß√£o Proposta |
|---|---|---|
| Volume de dados (4.430 treino) | Plateau de ensemble em 0,9987 com 4 modelos | Incorporar CheXpert / NIH ChestX-ray14 |
| Grad-CAM n√£o implementado | Interpretabilidade apenas indireta | Hook em `features.norm5` + valida√ß√£o cl√≠nica |
| Calibra√ß√£o n√£o avaliada | Probabilidades podem ser mal calibradas para triagem | Expected Calibration Error (ECE) |
| Dataset de fonte √∫nica | Generaliza√ß√£o inter-institucional n√£o testada | Teste em dados de equipamentos distintos |
| Folds de ~880 amostras | Dif√≠cil discriminar ganhos < 0,001 AUC | Maior dataset ou bootstrap CI |

> **Experimento negativo documentado:** pipeline sem StratifiedGroupKFold atingiu AUC=1,0000 em valida√ß√£o interna mas colapsou no leaderboard Kaggle (AUC <0,981), confirmando empiricamente que o isolamento por paciente √© requisito inegoci√°vel, n√£o preciosismo metodol√≥gico.

---

## üë§ Autor

**Ivan Carvalho Ernesto Bezerra**  
Centro de Inform√°tica ‚Äì UFPE  
[iceb@cin.ufpe.br](mailto:iceb@cin.ufpe.br)

---

> *Se voc√™ est√° avaliando este reposit√≥rio e tiver a m√©trica de alguma submiss√£o que n√£o pude testar (esgotei o limite de submiss√µes no Kaggle), ficaria muito grato se pudesse me enviar por email. Obrigado!*

---

<div align="center">
<sub>Ligia ‚Äì Liga Acad√™mica de Intelig√™ncia Artificial ¬∑ UFPE ¬∑ 2026</sub>
</div>
